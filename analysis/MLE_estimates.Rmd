---
title: "MLE"
author: "Margarita Orlova"
date: "November 15, 2019"
output: html_document
---
# MLE estimates and sampling variability

In this section we infer point estimates $k_{on}$,$k_{off}$ and $k_r$ by maximum likelihood and estimate sampling variability of MLE. We used code provided by Larsson et al. publication.

Since the original code is in python, we have to source it as a script that generates data with same $k_{on}$,$k_{off}$ and $k_r$ 1000 times to get the point estimates. We repeat this process 4 times with different $k_{on}$,$k_{off}$ scenarios.

```{r, echo=FALSE}
library(reticulate)
source_python("C:/Users/Moonkin/Documents/GitHub/Thesis_single_RNA/analysis/MLE.py")
```


## I) Small $k_{on}$ and $k_{off}$ case:

```{r, echo=FALSE}
library(robustbase)
#True k_on=k_off=0.1
hist(log(est_1[,1]),breaks=30, main="MLE estimate of k_on parameter,1000 runs, true k_on=0.1, log scale")
abline(v=log(0.1),col='red')
hist(log(est_1[,2]),breaks=30, main="MLE estimate of k_off parameter,1000 runs, true k_off=0.1, log scale")
abline(v=log(0.1),col='red')
hist(log(est_1[,3]),breaks=30, main="MLE estimate of k_r parameter,1000 runs,true k_r=100, log scale")
abline(v=log(100),col='red')
paste("true k_on is 0.1;","k_on mean",round(mean(est_1[,1],na.rm=TRUE),3),"k_on median",round(median(est_1[,1],na.rm=TRUE),3))
paste("true k_off is 0.1;","k_off mean",round(mean(est_1[,2],na.rm=TRUE),3),"k_off median",round(median(est_1[,2],na.rm=TRUE),3))
paste("true k_r is 100;","k_r mean",round(mean(est_1[,3],na.rm=TRUE),3),"k_r median",round(median(est_1[,3],na.rm=TRUE),3))
```

Small $k_{on}$ and $k_{off}$ leads to bimodal distribution. As we see from histograms, mean and median MLE estimates are centered around true value.

## II) Large $k_{on}$ and $k_{off}$ case: 

```{r, echo=FALSE}
#True k_on=k_off=10
hist(log(est_2[,1]),breaks=30, main="MLE estimate of k_on parameter,1000 runs, true k_on=10, log scale")
abline(v=log(10),col='red')
hist(log(est_2[,2]),breaks=30, main="MLE estimate of k_off parameter,1000 runs, true k_off=10, log scale")
abline(v=log(10),col='red')
hist(log(est_2[,3]),breaks=30, main="MLE estimate of k_r parameter,1000 runs, true k_r=100, log scale")
abline(v=log(100),col='red')
paste("true k_on is 10;","k_on mean",round(mean(est_2[,1],na.rm=TRUE),3),"k_on median",round(median(est_2[,1],na.rm=TRUE),3))
paste("true k_off is 10;","k_off mean",round(mean(est_2[,2],na.rm=TRUE),3),"k_off median",round(median(est_2[,2],na.rm=TRUE),3))
paste("true k_r is 100;","k_r mean",round(mean(est_2[,3],na.rm=TRUE),3),"k_r median",round(median(est_2[,3],na.rm=TRUE),3))
```

Large $k_{on}$ and $k_{off}$ case lead to Poisson or negative binomial distribution and as we can see parameters are not identifiable.  

## III) Large value if $k_{off}$ and small $k_{on}$ case:

```{r, echo=FALSE}
#True k_on=1, k_off=10
hist(log(est_3[,1]),breaks=30, main="MLE estimate of k_on parameter,1000 runs, true k_on=1, log scale")
abline(v=log(1),col='red')
hist(log(est_3[,2]),breaks=30, main="MLE estimate of k_off parameter,1000 runs, true k_off=10, log scale")
abline(v=log(10),col='red')
hist(log(est_3[,3]),breaks=30, main="MLE estimate of k_r parameter,1000 runs, true k_r=100, log scale")
abline(v=log(100),col='red')
paste("true k_on is 1;","k_on mean",round(mean(est_3[,1],na.rm=TRUE),3),"k_on median",round(median(est_3[,1],na.rm=TRUE),3))
paste("true k_off is 10;","k_off mean",round(mean(est_3[,2],na.rm=TRUE),3),"k_off median",round(median(est_3[,2],na.rm=TRUE),3))
paste("true k_r is 100;","k_r mean",round(mean(est_3[,3],na.rm=TRUE),3),"k_r median",round(median(est_3[,3],na.rm=TRUE),3))
```

k_on parameter being estimated correctly, while k_off and k_r are non-identifiable.

## IV) Small value if $k_{off}$ and big $k_{on}$

```{r, echo=FALSE}
#True k_on=10, k_off=1
hist(log(est_4[,1]),breaks=30, main="MLE estimate of k_on parameter,1000 runs, true k_on=10, log scale")
abline(v=log(10),col='red')
hist(log(est_4[,2]),breaks=30, main="MLE estimate of k_off parameter,1000 runs, true k_off=1, log scale")
abline(v=log(1),col='red')
hist(log(est_4[,3]),breaks=30, main="MLE estimate of k_r parameter,1000 runs, true k_r=100, log scale")
abline(v=log(100),col='red')
paste("true k_on is 10;","k_on mean",round(mean(est_4[,1],na.rm=TRUE),3),"k_on median",round(median(est_4[,1],na.rm=TRUE),3))
paste("true k_off is 1;","k_off mean",round(mean(est_4[,2],na.rm=TRUE),3),"k_off median",round(median(est_4[,2],na.rm=TRUE),3))
paste("true k_r is 100;","k_r mean",round(mean(est_4[,3],na.rm=TRUE),3),"k_r median",round(median(est_4[,3],na.rm=TRUE),3))
```



Ref.
https://www.nature.com/articles/s41586-018-0836-1
